{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a Quality Assurance Classifier for Engineering Corps ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Pandas to understand what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>Date and Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 11:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 12:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19/07/2008 13:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 14:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>19/07/2008 15:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels        Date and Time\n",
       "0      -1  19/07/2008 11:55:00\n",
       "1      -1  19/07/2008 12:32:00\n",
       "2       1  19/07/2008 13:17:00\n",
       "3      -1  19/07/2008 14:43:00\n",
       "4      -1  19/07/2008 15:22:00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.data', names=['labels', 'Date and Time'], sep=' ', infer_datetime_format=True)\n",
    "measurements = pd.read_csv('measurements.data', header=None, sep=' ')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above we have labels for failure as well as date and time for each reading. Successfully loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1          2          3       4      5         6       7    \\\n",
       "0  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   97.6133  0.1242   \n",
       "1  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0  102.3433  0.1247   \n",
       "2  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   95.4878  0.1241   \n",
       "3  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0  104.2367  0.1217   \n",
       "4  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0  100.3967  0.1235   \n",
       "\n",
       "      8       9      ...        580       581     582     583     584  \\\n",
       "0  1.5005  0.0162    ...        NaN       NaN  0.5005  0.0118  0.0035   \n",
       "1  1.4966 -0.0005    ...     0.0060  208.2045  0.5019  0.0223  0.0055   \n",
       "2  1.4436  0.0041    ...     0.0148   82.8602  0.4958  0.0157  0.0039   \n",
       "3  1.4882 -0.0124    ...     0.0044   73.8432  0.4990  0.0103  0.0025   \n",
       "4  1.5031 -0.0031    ...        NaN       NaN  0.4800  0.4766  0.1045   \n",
       "\n",
       "       585     586     587     588       589  \n",
       "0   2.3630     NaN     NaN     NaN       NaN  \n",
       "1   4.4447  0.0096  0.0201  0.0060  208.2045  \n",
       "2   3.1745  0.0584  0.0484  0.0148   82.8602  \n",
       "3   2.0544  0.0202  0.0149  0.0044   73.8432  \n",
       "4  99.3032  0.0202  0.0149  0.0044   73.8432  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It should be noted that:\n",
    "1. There is 590 columns of sensor data here which does not correspond to the 591 different sensors stated in the brief sheet. Upon visual inspection of the data file I cannot see discrepancies in the way pandas has loaded it.\n",
    "2. The data is currently expressed in many different scales and so feature scaling will be required, prior to any machine learning.\n",
    "3. There are missing NaN values in the sensor data that must be accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the measurements dataframe is (1567, 590)\n",
      "The size of float_check is (590,) and the sum of columns that are floats are 590\n",
      "Meaning all sensor data in the measurements file is numeric and there are 1567 samples per sensor.\n"
     ]
    }
   ],
   "source": [
    "print('The size of the measurements dataframe is ' + str(measurements.values.shape))\n",
    "float_check = measurements.dtypes == np.float64\n",
    "print('The size of float_check is ' + str(float_check.shape) + \" and the sum of columns that are floats are \" + str(float_check.sum()))\n",
    "print('Meaning all sensor data in the measurements file is numeric and there are 1567 samples per sensor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the labels dataframe is (1567, 2)\n",
      "The data types contained in the labels dataframe is \n",
      "labels            int64\n",
      "Date and Time    object\n",
      "dtype: object\n",
      "The number of sensor samples in labels, matches the samples in measurements which is a good sanity check. It also means each timestamp corresponds to the sensor measurements.\n"
     ]
    }
   ],
   "source": [
    "print('The size of the labels dataframe is ' + str(labels.values.shape))\n",
    "print('The data types contained in the labels dataframe is \\n' + str(labels.dtypes))\n",
    "print('The number of sensor samples in labels, matches the samples in measurements which is a good sanity check. It also means each timestamp corresponds to the sensor measurements.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values = 41951\n",
      "Total values = 924530\n",
      "Percentage values missing = 4.537548808583821%\n"
     ]
    }
   ],
   "source": [
    "print('Missing values = ' + str(measurements.isnull().sum(axis = 0).sum()))\n",
    "print('Total values = ' + str(measurements.values.size))\n",
    "percentage_missing = 100*measurements.isnull().sum(axis = 0).sum()/measurements.values.size\n",
    "print('Percentage values missing = ' + str(percentage_missing) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "1. 4.5% of all the data is missing.\n",
    "2. I will make an assumption to replace this missing data with the mean values in each column.\n",
    "3. I will do this after mean normalisation so as to not affect the standard deviation.\n",
    "4. I believe this will not affect the results too much because I will be mean-normalising the data anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data = measurements.values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalisation(X):\n",
    "    mu = np.nanmean(X, axis=0)\n",
    "    sigma = np.nanstd(X, axis=0)\n",
    "    X_norm = (X[:,]-mu)/sigma\n",
    "    return mu, sigma, X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22387917  0.8478245  -0.43431977 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 1.10501484 -0.38205392  1.01258264 ...  0.41172174  0.25004455\n",
      "   1.15631999]\n",
      " [-1.11202304  0.79731564 -0.47913456 ...  3.62590582  3.32035899\n",
      "  -0.17909141]\n",
      " ...\n",
      " [-0.48429031 -1.44398414  0.19498206 ... -0.89439547 -0.97110324\n",
      "  -0.59818675]\n",
      " [-1.62412795  0.44984948 -0.79698678 ...  0.91145354  0.7733936\n",
      "  -0.06579841]\n",
      " [-0.94476352 -0.56094985 -0.17295887 ... -0.03122236 -0.2733045\n",
      "   0.40606805]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\as166\\Anaconda3\\envs\\monolith_env\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "mu, sigma, sensor_data_norm = mean_normalisation(sensor_data)\n",
    "\n",
    "# Setting nan values to zero now that the data has been feature scaled. (Equivalent to setting to mean) \n",
    "nan_rows, nan_cols = np.where(np.isnan(sensor_data_norm))\n",
    "sensor_data_norm[nan_rows, nan_cols]=0\n",
    "print(sensor_data_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and process labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 0 0]\n",
      "%success = 6.636885768985322\n"
     ]
    }
   ],
   "source": [
    "sensor_labels = labels['labels'].values.copy()\n",
    "sensor_labels[sensor_labels>0] = 1\n",
    "sensor_labels[sensor_labels<0] = 0\n",
    "print(sensor_labels)\n",
    "success_rate = 100*sensor_labels.sum()/sensor_labels.size\n",
    "print('%success = ' + str(success_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "1. Labelled data is very skewed, meaning very few success rates. This will be hard to train with a typical classifier, also must take extra care when assessing precision and recall.\n",
    "2. Could be worth removing successes and training an anomally detection algorithm instead with success as the anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with a Supervised Learning Problem\n",
    ". Lets split the data set into train, test and cross validation, ensuring there is an even proportion of successes in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the sensor data and labels, note you are ignoring effects of time.\n",
    "# idx = np.arange(sensor_data_norm.shape[0])\n",
    "# np.random.shuffle(idx)\n",
    "# sensor_data_norm_shuffled = sensor_data_norm[idx, :]\n",
    "# sensor_labels_shuffled = sensor_labels[idx]\n",
    "\n",
    "# success_locs = np.where(sensor_labels_shuffled == 1)\n",
    "# failure_locs = np.where(sensor_labels_shuffled == 0)\n",
    "# success_locs = success_locs[0]\n",
    "# failure_locs = failure_locs[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939\n",
      "(877,)\n"
     ]
    }
   ],
   "source": [
    "# num_success_trainset = np.floor(success_locs.shape[0]*0.6).astype(int)\n",
    "# num_success_cross_val = np.floor(success_locs.shape[0]*0.2).astype(int)\n",
    "\n",
    "# num_failure_trainset = np.floor(failure_locs.shape[0]*0.6).astype(int)\n",
    "# num_failure_cross_val = np.floor(failure_locs.shape[0]*0.2).astype(int)\n",
    "# print(num_success_trainset + num_failure_trainset)\n",
    "# print(failure_locs[:num_failure_trainset].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(939, 590)\n"
     ]
    }
   ],
   "source": [
    "# trainset_X = sensor_data_norm_shuffled[success_locs[:num_success_trainset], :]\n",
    "# #print(sensor_data_norm_shuffled[failure_locs[:num_failure_trainset], :].shape)\n",
    "# trainset_X = np.vstack((trainset_X, sensor_data_norm_shuffled[failure_locs[:num_failure_trainset], :]))\n",
    "# print(trainset_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 590)\n"
     ]
    }
   ],
   "source": [
    "# end_cross_val = num_success_cross_val+num_success_trainset\n",
    "# cross_val_X = sensor_data_norm_shuffled[success_locs[num_success_trainset:end_cross_val], :]\n",
    "# cross_val_X = np.vstack((cross_val_X, sensor_data_norm_shuffled[failure_locs[num_failure_cross:end_cross_val],:]))\n",
    "# print(cross_val_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset_X = sensor_data_norm_shuffled[success_locs[:num_success_cross_val], :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Monolith_env)",
   "language": "python",
   "name": "monolith_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
